{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncf-isp2020-nlmlp-day2-student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG6A2L7-jUwB"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "Clone GitHub repository to Colab storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXLCNpOZiyAs"
      },
      "source": [
        "!git clone https://github.com/megagonlabs/HappyDB.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUYf9g9_jFKH"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WasmXyADjHT7"
      },
      "source": [
        "!ls HappyDB/happydb/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjO7kzYIfWun"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fixxp-40pQ3p"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.base import clone\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def run_cv(X, y, clf, num_classes):\n",
        "  kf = KFold(n_splits=5, random_state=1)\n",
        "  cm = np.zeros([num_classes,\n",
        "                  num_classes],\n",
        "                  dtype=\"int\") # Initialize confusion matrix with 0\n",
        "  f1_list = []\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    print(\"Fold {}\".format(i + 1))\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    cur_clf = clone(clf)\n",
        "    cur_clf.fit(X_train, y_train)\n",
        "    y_pred = cur_clf.predict(X_test)\n",
        "    cm += confusion_matrix(y_test, y_pred)\n",
        "    f1_list.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "  f1_scores = np.array(f1_list)\n",
        "  return (f1_scores, cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsnWtFElj3_v"
      },
      "source": [
        "## Loading CSV file as DataFrame\n",
        "\n",
        "Use `.read_csv()` function to load a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFwKyYpYigFM"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kijkbc5i9ap"
      },
      "source": [
        "hm_df = pd.read_csv(\"HappyDB/happydb/data/cleaned_hm.csv\")\n",
        "hm_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O3TGhi0kLA0"
      },
      "source": [
        "# Filtering out samples that do not have ground truth labels\n",
        "#   or # of sentences > 3\n",
        "filtered_hm_df = hm_df[(hm_df[\"num_sentence\"] <= 3) &\n",
        "                       (~ hm_df[\"ground_truth_category\"].isnull())]\n",
        "                       \n",
        "print(\"Original # of HM: {}\".format(len(hm_df)))\n",
        "print(\"Filtered # of HM: {}\".format(len(filtered_hm_df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt69LV3HlsAe"
      },
      "source": [
        "# Label vector & Feature matrix creation\n",
        "\n",
        "Let's create label vector and feature matrix from the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-dsqTP0mGC2"
      },
      "source": [
        "# Label Encoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(filtered_hm_df[\"ground_truth_category\"])\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAH1JBYWmyKX"
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jkSMjEXC_g-"
      },
      "source": [
        "Xcount = CountVectorizer().fit_transform(filtered_hm_df[\"cleaned_hm\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaSNosohEXOg"
      },
      "source": [
        "# Try other feature extraction methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4L7katmm0uV"
      },
      "source": [
        "%%time\n",
        "# Creates feature vectors\n",
        "Xtfidf = TfidfVectorizer().fit_transform(filtered_hm_df[\"cleaned_hm\"])\n",
        "Xlda = LatentDirichletAllocation().fit_transform(\n",
        "        CountVectorizer().fit_transform(filtered_hm_df[\"cleaned_hm\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqXEpAlmjfI6"
      },
      "source": [
        "Xcount_lda = np.concatenate([Xcount.todense(), Xlda], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIGmCFCMf2RL"
      },
      "source": [
        "f1_scores_count, _ = run_cv(Xcount, y, LogisticRegression(), len(le.classes_))\n",
        "f1_scores_tfidf, _ = run_cv(Xtfidf, y, LogisticRegression(), len(le.classes_))\n",
        "f1_scores_lda, _ = run_cv(Xlda, y, LogisticRegression(), len(le.classes_))\n",
        "f1_scores_count_lda, _ = run_cv(Xcount_lda, y, LogisticRegression(), len(le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrYVj7ipgJGf"
      },
      "source": [
        "eval_df = pd.DataFrame({\"CountVec\": f1_scores_count,\n",
        "                        \"TfidfVec\": f1_scores_tfidf,\n",
        "                        \"LDA\": f1_scores_lda,\n",
        "                        \"Count+LDA\": f1_scores_count_lda})\n",
        "eval_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILyE7FQnlib_"
      },
      "source": [
        "Try!\n",
        "- Try different configurations of `CountVectorizer()` `TfidfVectorizer()` `LatentDirichletAllocation()`.\n",
        "- Replace `LogisticRegression()` with other algorithms.\n",
        "- Replace `LogisticRegression()` wigh `GridSearchCV(LogisticRegression(), ...)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vmUvy8wmid0"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample code from spaCy\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "info_list = []\n",
        "for token in doc:\n",
        "    info_list.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop])\n",
        "pd.DataFrame(\n",
        "    info_list, columns=[\"TEXT\", \"LEMMA\", \"POS\", \"TAG\", \"DEP\", \"SHAPE\", \"ALPHA\", \"STOP\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9IMcGmDk-y"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Use the following ideas as preprocessing\n",
        "- Remove stop words\n",
        "- Filter adjectives, nouns, and verbs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhnBIMjPmmc-"
      },
      "source": [
        "pos_set = [\"ADJ\", \"PROPN\", \"NOUN\", \"VERB\"]\n",
        "proc_hm_list = []\n",
        "for hm in filtered_hm_df[\"cleaned_hm\"].tolist():\n",
        "  filtered_tokens = []\n",
        "  for token in nlp(hm):\n",
        "    # Remove stop words\n",
        "    if token.is_stop:\n",
        "      continue\n",
        "    # Filter tokens that belong to predefined POS types\n",
        "    if token.pos_ not in pos_set:\n",
        "      continue\n",
        "    filtered_tokens.append(token.lemma_)\n",
        "  proc_hm = \" \".join(filtered_tokens)\n",
        "  proc_hm_list.append(proc_hm)\n",
        "filtered_hm_df[\"proc_hm\"] = proc_hm_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXm3NDi8nDXQ"
      },
      "source": [
        "filtered_hm_df[\"proc_hm\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOJt8HwV2aVO"
      },
      "source": [
        "Xcount_proc = CountVectorizer().fit_transform(filtered_hm_df[\"proc_hm\"])\n",
        "f1_scores_count_proc, _ = run_cv(Xcount_proc, y, LogisticRegression(), len(le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzNyKN2C2pKx"
      },
      "source": [
        "eval_df = pd.DataFrame({\"CountVec\": f1_scores_count,\n",
        "                        \"TfidfVec\": f1_scores_tfidf,\n",
        "                        \"LDA\": f1_scores_lda,\n",
        "                        \"Count+LDA\": f1_scores_count_lda,\n",
        "                        \"Proc+CountVec\": f1_scores_count_proc})\n",
        "eval_df.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}